# -*- coding: utf-8 -*-
"""Regressão Logística - Concessão de Crédito.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1NsrUuhAcJMwc9Y2i3OFMSyc9Vwz9fudD

#Regressão Logística - Concessão de Crédito

O objetivo do estudo abaixo é apresentar o uso de regressão logística para análise preditiva para concessão de crédito, utilizando diferentes algoritmos e comparando seus indicadores de desempenho.

**Fonte de dados:** Dataset público extraído originalmente do Kaggle e traduzido para o português.

##Importação de Bibliotecas
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import RandomForestClassifier 

from xgboost import XGBClassifier

from sklearn.metrics import accuracy_score
from sklearn.metrics import plot_confusion_matrix
from sklearn.metrics import classification_report
from sklearn.metrics import roc_curve, roc_auc_score

"""##Funções """

def tranforma_coluna_categorica_em_numerica(dataset, lista_coluna):

  for coluna in lista_coluna:

    lista = list(enumerate(dataset[coluna].unique()));

    dicionario = {};

    for item in lista:
      dicionario.update({item[1]: item[0]})

    dataset['id_' + coluna] = dataset[coluna].map(dicionario)

  return dataset

#funcao 'roda_modelo': ajuste a validacao

def roda_modelo(base_dados, classificador):

#separando a base de modelagem e variavel resposta

    y = base_dados['default']
    x = base_dados.drop(columns='default')

#separando a base de treino e teste

    SEED = 77
    treino_x, teste_x, treino_y, teste_y = train_test_split(x, y, test_size=0.30, random_state = SEED)

    base_treino = treino_x.shape[0]
    base_teste = teste_x.shape[0]
    print('A base de treino tem %s elementos e a base de teste tem %s elementos.' %(base_treino, base_teste))
    print(100*'-')

#ajustamdo modelo com base de teste
    
    modelo = classificador
    modelo.fit(treino_x, treino_y)

#-------------------------------------------------------------------------------------------------------------------------------------

#matriz de confusao

    matriz_confusao = plot_confusion_matrix(modelo, teste_x, teste_y, values_format = '.3g', cmap = 'Blues')
    plt.title('Matriz de Confusao')
    plt.show

#classification report

    previsoes = modelo.predict(teste_x)

    print('\nClassification Report:')
    print(classification_report(teste_y, previsoes))

#curva ROC  e AUC

    print(100*'-')
    prob_previsao = modelo.predict_proba(teste_x)[:,1]
   
    tfp, tvp, limite = roc_curve(teste_y, prob_previsao)
    print('roc_auc:', roc_auc_score(teste_y, prob_previsao))
    
    plt.subplots(1, figsize=(5,5))
    plt.title('Curva ROC')
    plt.plot(tfp, tvp)
    plt.plot([0, 1], ls="--", c = 'red') #plotando linha pontilhada guia para regressao aleatoria
    plt.plot([0, 0], [1, 0], ls="--", c = 'green'), plt.plot([1, 1], ls="--", c = 'green') #plotando linha pontilhada guia para regressao perfeita
    plt.ylabel('Sensibilidade')
    plt.xlabel('Especificidade')
    plt.show() 

    return modelo, matriz_confusao

"""##Carga dos Dados"""

dados_origem = pd.read_csv('base_dados_traduzida.csv')
dados_origem.head()

dados_origem.info()

linhas = dados_origem.shape[0]
colunas = dados_origem.shape[1]

print('A base de dados tem %s linhas e %s colunas.' %(linhas, colunas))

"""##Tratamento e Preparação dos Dados"""

duplicados = dados_origem.duplicated()
duplicados = duplicados.sum()

print('A base de dados tem %s dados duplicados.' %(duplicados))

nulos = dados_origem.isnull()
nulos.sum()

lista_coluna = ['conta_corrente', 'historico_credito', 'proposito_emprestimo', 'reserva_cc', 'tempo_emprego_atual', 
                'sexo_est_civil', 'outros_fiadores', 'propriedade', 'outros_planos_financiamento', 'tipo_residencia', 
                'status_emprego', 'telefone', 'trabalhador_estrangeiro']

dados = tranforma_coluna_categorica_em_numerica(dados_origem.copy(), lista_coluna)
dados.drop(columns=lista_coluna, inplace=True)
dados.head()

"""##Preparação das bases de treino e testes"""

y = dados['default']
y.head()

x = dados.drop(columns = ['default'])
x.head()

SEED = 77
treino_x, teste_x, treino_y, teste_y = train_test_split(x, y, test_size = 0.30, random_state = SEED)

base_treino = treino_x.shape[0]
base_teste = teste_x.shape[0]

print('A base de treino tem %s elementos e a base de teste tem %s elementos.' %(base_treino, base_teste))

"""##Execução dos Modelos de Machine Learning"""

modelo = LogisticRegression(max_iter=1000)
modelo.fit(treino_x, treino_y) 
print(modelo.score(treino_x, treino_y))

previsoes = modelo.predict(teste_x)
previsoes

acuracia = accuracy_score(teste_y, previsoes)
acuracia = round(acuracia, 3)*100
acuracia

matriz_confusao = plot_confusion_matrix(modelo, teste_x, teste_y, cmap='Blues', values_format = '.3g')
matriz_confusao

print(classification_report(teste_y, previsoes))

prob_previsao = modelo.predict_proba(teste_x)[:,1]

#tfp = taxa falsos positivos
#tvp = taxa verdadeiros positivos

tfp, tvp, limite = roc_curve(teste_y, prob_previsao)
print('roc_auc', roc_auc_score(teste_y, prob_previsao))

plt.subplots(1, figsize=(5,5))
plt.title('Curva ROC')
plt.plot(tfp,tvp)
plt.xlabel('Especifidade')
plt.ylabel('Sensibilidade')
plt.plot([0, 1], ls="--", c = 'red') #plotando linha guia pontilhada vermelha
plt.plot([0, 0], [1, 0], ls="--", c = 'green'), plt.plot([1, 1], ls="--", c = 'green') #plotando linha guia pontilhada verde
plt.show()

dados_origem['default'].value_counts()

dados_origem['sexo_est_civil'].value_counts()

histogramas = ['id_sexo_est_civil', 'prazo_emprestimo_meses', 'default']

lista_histogramas = list(enumerate(histogramas))

plt.figure(figsize = (30,20))

for i in lista_histogramas:
    plt.subplot(2, 2, i[0]+1)
    sns.countplot(x = i[1], data = dados)

plt.figure(figsize = (20,10))

sns.boxplot(x = 'id_sexo_est_civil', y = 'idade', data = dados)
plt.title('Distribuicao de idadade por sexo e estado civil')

plt.show()

plt.figure(figsize = (20,10))

plt.bar(dados.prazo_emprestimo_meses, dados.valor_emprestimo)

plt.xlabel('prazo_emprestimo_meses')
plt.ylabel('valor_emprestimo')
plt.title('Valor X prazo em meses')

plt.show()

"""##Simulação com 5 amostras apenas"""

a_x = teste_x.head()
a_y = teste_y.head()
a_y

a_prev = modelo.predict(a_x)
a_prev

print(classification_report(a_y, a_prev))

a_prob = modelo.predict_proba(a_x)
a_prob

"""##Matriz de correlação"""

dados.corr()

plt.matshow(dados.corr())
plt.show()

"""##Comparação entre Diferentes Modelos de Machine Learning

###Regressão Logística
"""

roda_modelo(dados, LogisticRegression(max_iter=1000))

"""###KNN"""

roda_modelo(dados, KNeighborsClassifier())

"""###Random Forest"""

roda_modelo(dados, RandomForestClassifier (n_estimators = 1000, random_state = 42))

"""###Gradient Boosting"""

roda_modelo(dados, XGBClassifier(learning_rate = 0.1, n_estimators=1000, max_depth=6,
                                 min_child_weight=1, gamma=0, subsample=0.8, colsample_bytree=0.8,
                                 objective= 'binary:logistic', nthread=4, scale_pos_weight=1.0, seed=27))

"""##Análise dos Modelos de Machine Learning"""

Com base na execução dos modelos com o dataset objeto deste estudo, o algoritmo que apresentou melhor desempenho foi o